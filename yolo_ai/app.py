from flask import Flask, request, jsonify
from flask_cors import CORS
import torch
import os
import logging
import cv2
import numpy as np
from PIL import Image

# Flask ì„¤ì •
app = Flask(__name__)
CORS(app)  # CORS í—ˆìš© (ëª¨ë°”ì¼ ë° ì›¹ì—ì„œ API í˜¸ì¶œ ê°€ëŠ¥)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)

# YOLOv5 ëª¨ë¸ ë¡œë“œ
MODEL_PATH = "./yolov5-master/runs/train/exp6/weights/best.pt"
model = torch.hub.load('./yolov5-master', 'custom', path=MODEL_PATH, source='local')
model.eval()  # ì¶”ë¡  ëª¨ë“œ ì„¤ì •

# ì´ë¯¸ì§€ ì €ì¥ í´ë” ìƒì„±
UPLOAD_FOLDER = "uploads"
PROCESSED_FOLDER = "processed"
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(PROCESSED_FOLDER, exist_ok=True)

def draw_bounding_boxes(image_path, detections):
    """ ê°ì§€ëœ ê°ì²´ì— ëŒ€í•œ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦° í›„ ì´ë¯¸ì§€ ì €ì¥ """
    # ì´ë¯¸ì§€ ë¡œë“œ (OpenCV ì‚¬ìš©)
    image = cv2.imread(image_path)
    if image is None:
        return None  # ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
    
    # ë°”ìš´ë”© ë°•ìŠ¤ ìƒ‰ìƒ ë° í°íŠ¸ ì„¤ì •
    color = (0, 255, 0)  # ì´ˆë¡ìƒ‰
    font = cv2.FONT_HERSHEY_SIMPLEX

    for det in detections:
        x_min, y_min, x_max, y_max = int(det["xmin"]), int(det["ymin"]), int(det["xmax"]), int(det["ymax"])
        label = f"{det['name']} ({det['confidence']*100:.2f}%)"

        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, 2)

        # ë¼ë²¨ í…ìŠ¤íŠ¸ ì¶”ê°€
        cv2.putText(image, label, (x_min, y_min - 10), font, 0.5, color, 2)

    # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
    processed_path = os.path.join(PROCESSED_FOLDER, os.path.basename(image_path))
    cv2.imwrite(processed_path, image)
    
    return processed_path

@app.before_request
def log_request_info():
    print(f"ğŸ“¡ ìš”ì²­: {request.method} {request.url}")
    print(f"ğŸ“‹ í—¤ë”: {request.headers}")
    print(f"ğŸ“‚ ë°ì´í„°: {request.data}")

@app.route('/')
def home():
    return "<h1>YOLOv5 Flask App</h1><p>API is running. Use the correct endpoint for predictions.</p>"

@app.route('/detect', methods=['POST'])
def detect():
    if 'image' not in request.files:
        return jsonify({"error": "No image provided"}), 400
    
    file = request.files['image']
    try:
        # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥
        file_path = os.path.join(UPLOAD_FOLDER, file.filename)
        file.save(file_path)

        # YOLOv5 ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰
        image = Image.open(file.stream)
        results = model(image)
        detections = results.pandas().xyxy[0].to_dict(orient="records")
        
        # ê°ì²´ ì¢…ë¥˜ë³„ë¡œ ê°œìˆ˜ë¥¼ ì¹´ìš´íŠ¸
        object_counts = {}
        for detection in detections:
            label = detection.get("name")
            if label:
                object_counts[label] = object_counts.get(label, 0) + 1

        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦° ì´ë¯¸ì§€ ì €ì¥ (í•„ìš”ì‹œ)
        processed_image_path = draw_bounding_boxes(file_path, detections)

        logging.info(f"Detections: {object_counts}")

        # í‚¤:ê°’ í˜•íƒœì˜ ê°ì²´ ê°œìˆ˜ ë°˜í™˜
        return jsonify(object_counts), 200
    except Exception as e:
        logging.error(f"Error: {str(e)}")
        return jsonify({"error": str(e)}), 500

=======
from PIL import Image
import mysql.connector
from openai import OpenAI
import config

# Flask ì„¤ì •
app = Flask(__name__)
CORS(app)  # CORS í—ˆìš©

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)

# YOLOv5 ëª¨ë¸ ë¡œë“œ
MODEL_PATH = "./yolov5-master/runs/train/exp6/weights/best.pt"
model = torch.hub.load('./yolov5-master', 'custom', path=MODEL_PATH, source='local')
model.eval()

# ì´ë¯¸ì§€ ì €ì¥ í´ë”
UPLOAD_FOLDER = "uploads"
PROCESSED_FOLDER = "processed"
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(PROCESSED_FOLDER, exist_ok=True)

# OpenAI í´ë¼ì´ì–¸íŠ¸ (í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY í•„ìš”)
client = OpenAI(api_key=config.OPENAI_API_KEY)

# MySQL ì—°ê²°
def get_db():
    return mysql.connector.connect(
        host="localhost",
        user="root",
        password="0340",
        database="data",
        charset="utf8mb4"
    )

# ========= YOLO ê´€ë ¨ í•¨ìˆ˜ =========
def draw_bounding_boxes(image_path, detections):
    image = cv2.imread(image_path)
    if image is None:
        return None
    
    color = (0, 255, 0)
    font = cv2.FONT_HERSHEY_SIMPLEX

    for det in detections:
        x_min, y_min, x_max, y_max = int(det["xmin"]), int(det["ymin"]), int(det["xmax"]), int(det["ymax"])
        label = f"{det['name']} ({det['confidence']*100:.2f}%)"
        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, 2)
        cv2.putText(image, label, (x_min, y_min - 10), font, 0.5, color, 2)

    processed_path = os.path.join(PROCESSED_FOLDER, os.path.basename(image_path))
    cv2.imwrite(processed_path, image)
    return processed_path

# ========= ë ˆì‹œí”¼ ê´€ë ¨ í•¨ìˆ˜ =========
def load_steps(recipe_id: str):
    conn = get_db()
    cur = conn.cursor(dictionary=True)
    cur.execute(
        "SELECT step_number, description FROM recipe_order "
        "WHERE recipe_id = %s ORDER BY step_number ASC",
        (recipe_id,)
    )
    rows = cur.fetchall()
    cur.close()
    conn.close()
    return rows

def chat_with_recipe(recipe_id: str, user_message: str) -> str:
    steps = load_steps(recipe_id)
    if not steps:
        return "í•´ë‹¹ ë ˆì‹œí”¼ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    context = "[Steps]\n"
    for s in steps:
        desc = s["description"].lstrip("0123456789.) ").strip()
        context += f"{s['step_number']}) {desc}\n"

    system_rule = """ë„ˆëŠ” 'ë ˆì‹œí”¼ ì „ìš© ì•ˆë‚´ë´‡'ì´ë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì˜¤ì§ ì•„ë˜ ì œê³µëœ ë ˆì‹œí”¼ ë³¸ë¬¸(steps)ì— ê·¼ê±°í•´ì„œë§Œ í•œêµ­ì–´ë¡œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ë‹µí•´ë¼.
ë³¸ë¬¸ì— ì—†ëŠ” ë‚´ìš©ì€ 'ë ˆì‹œí”¼ì— ì—†ìŒ'ì´ë¼ê³  ë§í•´ë¼.
ì§ˆë¬¸ì´ ëª¨í˜¸í•˜ë©´ ë ˆì‹œí”¼ ë²”ìœ„ ì•ˆì—ì„œ í•„ìš”í•œ ìµœì†Œí•œì˜ ì¶”ê°€ ì§ˆë¬¸ë§Œ í•´ë¼.
"""

    resp = client.responses.create(
        model="gpt-5-nano",
        input=[
            {"role": "system", "content": system_rule},
            {"role": "assistant", "content": context},
            {"role": "user", "content": user_message}
        ]
    )
    return resp.output_text

# ========= ë¼ìš°íŠ¸ =========
@app.route('/')
def home():
    return "<h1>Flask App</h1><p>YOLO + Recipe Chat API is running.</p>"

@app.route('/detect', methods=['POST'])
def detect():
    if 'image' not in request.files:
        return jsonify({"error": "No image provided"}), 400
    
    file = request.files['image']
    try:
        file_path = os.path.join(UPLOAD_FOLDER, file.filename)
        file.save(file_path)

        image = Image.open(file.stream)
        results = model(image)
        detections = results.pandas().xyxy[0].to_dict(orient="records")
        
        object_counts = {}
        for detection in detections:
            label = detection.get("name")
            if label:
                object_counts[label] = object_counts.get(label, 0) + 1

        processed_image_path = draw_bounding_boxes(file_path, detections)
        logging.info(f"Detections: {object_counts}")

        return jsonify(object_counts), 200
    except Exception as e:
        logging.error(f"Error: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/recipes/<recipe_id>/chat", methods=["POST"])
def recipe_chat(recipe_id):
    data = request.get_json()
    message = data.get("message", "")
    if not message:
        return jsonify({"error": "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"}), 400
    answer = chat_with_recipe(recipe_id, message)
    return jsonify({"answer": answer}), 200

# ========= ì‹¤í–‰ =========
>>>>>>> branch 'main' of https://github.com/JHTek/capstone-2025-MyFridge.git
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
